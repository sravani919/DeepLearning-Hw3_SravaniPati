{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b153c322-728a-4a6d-9b24-9cbd4c7baddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import transformers\n",
    "from transformers import BertModel, BertTokenizerFast, AdamW\n",
    "# AutoTokenizer, AutoModelForQuestionAnswering, BertTokenizer, BertForQuestionAnswering\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c87a19b-96cd-4c0e-a7d2-fbf77116d127",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(device)\n",
    "\n",
    "num_questions = 0\n",
    "num_posible = 0\n",
    "num_imposible = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d4f8d4-8c21-40e5-a5a5-5d04a3bb4aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_data(path): \n",
    "    #read each file and retrieve the contexts, qustions and answers\n",
    "    with open(path, 'rb') as f:\n",
    "        raw_data = json.load(f)\n",
    "    contexts = []\n",
    "    questions = []\n",
    "    answers = []\n",
    "    num_q = 0\n",
    "    num_pos = 0\n",
    "    num_imp = 0\n",
    "\n",
    "    for group in raw_data['data']:\n",
    "        for paragraph in group['paragraphs']:\n",
    "            context = paragraph['context']\n",
    "            for qa in paragraph['qas']:\n",
    "                question= qa['question']\n",
    "                num_q  = num_q  +1\n",
    "                for answer in qa['answers']:\n",
    "                    contexts.append(context.lower())\n",
    "                    questions.append(question.lower())\n",
    "                    answers.append(answer)\n",
    "    return num_q, num_pos, num_imp, contexts, questions, answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69089db-878f-4df3-a39c-20eb004a45a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_q, num_pos, num_imp, train_contexts, train_questions, train_answers = get_data('spoken_train-v1.1.json')\n",
    "num_questions  = num_q\n",
    "num_posible = num_pos\n",
    "num_imposible  = num_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6fb1448-a2e0-493e-bf21-c945d7b16a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_q, num_pos, num_imp, valid_contexts, valid_questions, valid_answers = get_data('spoken_test-v1.1.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6809d7ae-2b6c-4302-b2a7-952b13ac2173",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_answer_end(answers, contexts):\n",
    "    for answer, context in zip(answers, contexts):\n",
    "        answer['text'] = answer['text'].lower()\n",
    "        answer['answer_end'] = answer['answer_start'] + len(answer['text'])\n",
    "\n",
    "add_answer_end(train_answers, train_contexts)\n",
    "add_answer_end(valid_answers, valid_contexts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b52124c-7d43-4061-b56d-a42a19f71651",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 512\n",
    "MODEL_PATH = \"bert-base-uncased\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b58cba6-e633-4815-b128-c0f119115722",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "doc_stride = 128\n",
    "tokenizerFast = BertTokenizerFast.from_pretrained(MODEL_PATH)\n",
    "pad_on_right = tokenizerFast.padding_side == \"right\"\n",
    "train_contexts_trunc=[]\n",
    "print(len(train_contexts))\n",
    "for i in range(len(train_contexts)):\n",
    "    if(len(train_contexts[i])>512):\n",
    "        answer_start=train_answers[i]['answer_start']\n",
    "        answer_end=train_answers[i]['answer_start']+len(train_answers[i]['text'])\n",
    "        mid=(answer_start+answer_end)//2\n",
    "        para_start=max(0,min(mid - MAX_LENGTH//2,len(train_contexts[i])-MAX_LENGTH))\n",
    "        para_end = para_start + MAX_LENGTH \n",
    "        train_contexts_trunc.append(train_contexts[i][para_start:para_end])\n",
    "        train_answers[i]['answer_start']=((512/2)-len(train_answers[i])//2)\n",
    "    else:\n",
    "        train_contexts_trunc.append(train_contexts[i])  \n",
    "    \n",
    "print(len(train_contexts_trunc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a910e99-ca8f-46d4-ab25-e108b379784c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encodings_fast = tokenizerFast(train_questions, train_contexts_trunc,  max_length = MAX_LENGTH,truncation=True,\n",
    "        stride=doc_stride,\n",
    "        padding=True)\n",
    "valid_encodings_fast = tokenizerFast(valid_questions,valid_contexts,  max_length = MAX_LENGTH, truncation=True,stride=doc_stride,\n",
    "        padding=True)\n",
    "type(train_encodings_fast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c7feee-cfea-4bbc-82e7-fc570477ea25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ret_Answer_start_and_end_train(idx):\n",
    "    ret_start = 0\n",
    "    ret_end = 0\n",
    "    answer_encoding_fast = tokenizerFast(train_answers[idx]['text'],  max_length = MAX_LENGTH, truncation=True, padding=True)\n",
    "    for a in range( len(train_encodings_fast['input_ids'][idx]) -  len(answer_encoding_fast['input_ids']) ): #len(train_encodings_fast['input_ids'][0])):\n",
    "        match = True\n",
    "        for i in range(1,len(answer_encoding_fast['input_ids']) - 1):\n",
    "            if (answer_encoding_fast['input_ids'][i] != train_encodings_fast['input_ids'][idx][a + i]):\n",
    "                match = False\n",
    "                break\n",
    "            if match:\n",
    "                ret_start = a+1\n",
    "                ret_end = a+i+1\n",
    "                break\n",
    "    return(ret_start, ret_end)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1411599-a277-4ca0-aa2b-9062bde9b17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "start_positions = []\n",
    "end_positions = []\n",
    "ctr = 0\n",
    "for h in range(len(train_encodings_fast['input_ids'])):\n",
    "    s, e = ret_Answer_start_and_end_train(h)\n",
    "    start_positions.append(s)\n",
    "    end_positions.append(e)\n",
    "    if s==0:\n",
    "        ctr = ctr + 1\n",
    "    \n",
    "train_encodings_fast.update({'start_positions': start_positions, 'end_positions': end_positions})\n",
    "print(ctr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d885837-f401-4203-9f13-bb51be89fcdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ret_Answer_start_and_end_valid(idx):\n",
    "    ret_start = 0\n",
    "    ret_end = 0\n",
    "    answer_encoding_fast = tokenizerFast(valid_answers[idx]['text'],  max_length = MAX_LENGTH, truncation=True, padding=True)\n",
    "    for a in range( len(valid_encodings_fast['input_ids'][idx])  -  len(answer_encoding_fast['input_ids'])   ): #len(train_encodings_fast['input_ids'][0])):\n",
    "        match = True\n",
    "        for i in range(1,len(answer_encoding_fast['input_ids']) - 1):\n",
    "            if (answer_encoding_fast['input_ids'][i] != valid_encodings_fast['input_ids'][idx][a + i]):\n",
    "                match = False\n",
    "                break\n",
    "            if match:\n",
    "                ret_start = a+1\n",
    "                ret_end = a+i+1\n",
    "                break\n",
    "    return(ret_start, ret_end)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d10eab5-068f-4345-b665-482d501e81bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_positions = []\n",
    "end_positions = []\n",
    "ctr = 0\n",
    "for h in range(len(valid_encodings_fast['input_ids']) ):\n",
    "    #print(h)\n",
    "    s, e = ret_Answer_start_and_end_valid(h)\n",
    "    start_positions.append(s)\n",
    "    end_positions.append(e)\n",
    "    if s==0:\n",
    "        ctr = ctr + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4121d3da-7be6-4c9f-bdd8-44a7186efa2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_encodings_fast.update({'start_positions': start_positions, 'end_positions': end_positions})\n",
    "print(ctr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ab4346-b5c1-4836-be43-c971c9342348",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class InputDataset(Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "    def __getitem__(self, i):\n",
    "        return {\n",
    "            'input_ids': torch.tensor(self.encodings['input_ids'][i]),\n",
    "            'token_type_ids': torch.tensor(self.encodings['token_type_ids'][i]),\n",
    "            'attention_mask': torch.tensor(self.encodings['attention_mask'][i]),\n",
    "            'start_positions': torch.tensor(self.encodings['start_positions'][i]),\n",
    "            'end_positions': torch.tensor(self.encodings['end_positions'][i])\n",
    "        }\n",
    "    def __len__(self):\n",
    "        return len(self.encodings['input_ids'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7684a672-7a88-49f7-b612-7ee5d38ed7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_dataset = InputDataset(train_encodings_fast)\n",
    "valid_dataset = InputDataset(valid_encodings_fast)\n",
    "\n",
    "train_data_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "valid_data_loader = DataLoader(valid_dataset, batch_size=1)\n",
    "\n",
    "bert_model = BertModel.from_pretrained(MODEL_PATH)  #MODEL_PATH = \"bert-base-uncased\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efc8731-9a8f-4c81-8286-f157127da87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class QAModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(QAModel, self).__init__()\n",
    "        self.bert = bert_model\n",
    "        self.drop_out = nn.Dropout(0.1)\n",
    "        self.l1 = nn.Linear(768 * 2, 768 * 2)\n",
    "        self.l2 = nn.Linear(768 * 2, 2)\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            self.drop_out,\n",
    "            self.l1,\n",
    "            nn.LeakyReLU(),\n",
    "            self.l2 \n",
    "        )\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
    "        model_output = self.bert(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids, output_hidden_states=True)\n",
    "        hidden_states = model_output[2]\n",
    "        out = torch.cat((hidden_states[-1], hidden_states[-3]), dim=-1)  # taking Start logits from last BERT layer, End Logits from third to last layer\n",
    "        logits = self.linear_relu_stack(out)\n",
    "        \n",
    "        start_logits, end_logits = logits.split(1, dim=-1)\n",
    "        \n",
    "        start_logits = start_logits.squeeze(-1)\n",
    "        end_logits = end_logits.squeeze(-1)\n",
    "\n",
    "        return start_logits, end_logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e0d49a-a851-43ee-b8af-765f5856e78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = QAModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10134dda-5e83-45bb-92de-1461e11249dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# my function to manually calculate Cross Entropy Loss\n",
    "def loss_fn(start_logits, end_logits, start_positions, end_positions):\n",
    "    loss_fct = nn.CrossEntropyLoss()\n",
    "    start_loss = loss_fct(start_logits, start_positions)\n",
    "    end_loss = loss_fct(end_logits, end_positions)\n",
    "    total_loss = (start_loss + end_loss)/2\n",
    "    return total_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106c39c5-7025-47ce-8294-605e442a8559",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def focal_loss_fn(start_logits, end_logits, start_positions, end_positions, gamma):\n",
    "    \n",
    "    #calculate Probabilities by applying Softmax to the Start and End Logits. Then get 1 - probabilities\n",
    "    smax = nn.Softmax(dim=1)\n",
    "    probs_start = smax(start_logits)\n",
    "    inv_probs_start = 1 - probs_start\n",
    "    probs_end = smax(end_logits)\n",
    "    inv_probs_end = 1 - probs_end\n",
    "    \n",
    "    #get log of probabilities. Note: NLLLoss required log probabilities. This is the Natural Log (Log base e)\n",
    "    lsmax = nn.LogSoftmax(dim=1)\n",
    "    log_probs_start = lsmax(start_logits)\n",
    "    log_probs_end = lsmax(end_logits)\n",
    "    \n",
    "    nll = nn.NLLLoss()\n",
    "    \n",
    "    fl_start = nll(torch.pow(inv_probs_start, gamma)* log_probs_start, start_positions)\n",
    "    fl_end = nll(torch.pow(inv_probs_end, gamma)*log_probs_end, end_positions)\n",
    "    \n",
    "    #return mean of the Loss for the start and end logits\n",
    "    return ((fl_start + fl_end)/2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f6d2d6-01b6-4964-8e19-655b690f669b",
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = AdamW(model.parameters(), lr=2e-5, weight_decay=2e-2)\n",
    "EPOCHS = 3\n",
    "total_steps=len(train_dataset)*EPOCHS\n",
    "scheduler=transformers.get_linear_schedule_with_warmup(optim,num_warmup_steps=0,num_training_steps=total_steps )\n",
    "total_acc = []\n",
    "total_loss = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85077337-1a8b-4347-9ae9-baa4ebf95394",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, dataloader, epoch):\n",
    "    model = model.train()\n",
    "    losses = []\n",
    "    acc = []\n",
    "    ctr = 0\n",
    "    batch_tracker = 0\n",
    "    for batch in tqdm(dataloader, desc = 'Running Epoch '):\n",
    "        optim.zero_grad()\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        token_type_ids = batch['token_type_ids'].to(device)\n",
    "        start_positions = batch['start_positions'].to(device)\n",
    "        end_positions = batch['end_positions'].to(device)\n",
    "        out_start, out_end = model(input_ids=input_ids, \n",
    "                attention_mask=attention_mask,\n",
    "                token_type_ids=token_type_ids)\n",
    "        #loss = loss_fn(out_start, out_end, start_positions, end_positions)  # <---BASELINE.  Cross Entropy Loss is returned by Default\n",
    "        loss = focal_loss_fn(out_start, out_end, start_positions, end_positions,1) #using gamma = 1\n",
    "        losses.append(loss.item())\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        \n",
    "        start_pred = torch.argmax(out_start, dim=1)\n",
    "        end_pred = torch.argmax(out_end, dim=1)\n",
    "            \n",
    "        acc.append(((start_pred == start_positions).sum()/len(start_pred)).item())\n",
    "        acc.append(((end_pred == end_positions).sum()/len(end_pred)).item())\n",
    "        #ctr = ctr +1\n",
    "        #if ctr==50:\n",
    "        #    break\n",
    "        batch_tracker = batch_tracker + 1\n",
    "        if batch_tracker==250 and epoch==1:\n",
    "            total_acc.append(sum(acc))\n",
    "            loss_avg = sum(losses)/len(losses)\n",
    "            total_loss.append(loss_avg)\n",
    "            batch_tracker = 0\n",
    "    scheduler.step()\n",
    "    ret_acc = sum(acc)/len(acc)\n",
    "    ret_loss = sum(losses)/len(losses)\n",
    "    return(ret_acc, ret_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8031f07f-3767-4d4f-9fa8-c4c88bf2e897",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model, dataloader):\n",
    "    model = model.eval()\n",
    "    losses = []\n",
    "    acc = []\n",
    "    ctr = 0\n",
    "    answer_list=[]\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc = 'Running Evaluation'):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            token_type_ids = batch['token_type_ids'].to(device)\n",
    "            start_true = batch['start_positions'].to(device)\n",
    "            end_true = batch['end_positions'].to(device)\n",
    "            \n",
    "            out_start, out_end = model(input_ids=input_ids, attention_mask=attention_mask,token_type_ids=token_type_ids)\n",
    "            #print(\"out_start\",out_start.shape)\n",
    "            start_pred = torch.argmax(out_start)\n",
    "            end_pred = torch.argmax(out_end)\n",
    "            answer = tokenizerFast.convert_tokens_to_string(tokenizerFast.convert_ids_to_tokens(input_ids[0][start_pred:end_pred]))\n",
    "            tanswer = tokenizerFast.convert_tokens_to_string(tokenizerFast.convert_ids_to_tokens(input_ids[0][start_true[0]:end_true[0]]))\n",
    "            answer_list.append([answer,tanswer])\n",
    "            acc.append((start_pred == start_true).item())\n",
    "            acc.append((end_pred == end_true).item())\n",
    "        #ret_loss = sum(losses)/len(losses)\n",
    "    ret_acc = sum(acc)/len(acc)\n",
    "    print(f\"Test Accuracy: {ret_acc}\")\n",
    "    return answer_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ae7ed80f-bea0-4279-b214-3eb496c34ff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Epoch : 100%|██████████| 4639/4639 [04:47<00:00, 16.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.8026976257234998      Train Loss: 0.4356531048183837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Evaluation: 100%|██████████| 15875/15875 [02:44<00:00, 96.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.4788661417322835\n",
      "epoch  0 : 3.6526614173228347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Epoch : 100%|██████████| 4639/4639 [04:47<00:00, 16.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.8741974101598007      Train Loss: 0.24896675381434755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Evaluation: 100%|██████████| 15875/15875 [02:44<00:00, 96.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.4732283464566929\n",
      "epoch  1 : 3.6011338582677164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Epoch : 100%|██████████| 4639/4639 [04:47<00:00, 16.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.9119383795915633      Train Loss: 0.16659370167330337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Evaluation: 100%|██████████| 15875/15875 [02:44<00:00, 96.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.4810708661417323\n",
      "epoch  2 : 3.9240944881889765\n",
      "[3.6526614173228347, 3.6011338582677164, 3.9240944881889765]\n"
     ]
    }
   ],
   "source": [
    "from evaluate import load\n",
    "wer = load(\"wer\")\n",
    "model.to(device)\n",
    "wer_list=[]\n",
    "for epoch in range(EPOCHS):\n",
    "    train_acc, train_loss = train_epoch(model, train_data_loader, epoch+1)\n",
    "    print(f\"Train Accuracy: {train_acc}      Train Loss: {train_loss}\")\n",
    "    answer_list = eval_model(model, valid_data_loader)\n",
    "    pred_answers=[]\n",
    "    true_answers=[]\n",
    "    for i in range(len(answer_list)):\n",
    "        if(len(answer_list[i][0])==0):\n",
    "            answer_list[i][0]=\"$\"\n",
    "        if(len(answer_list[i][1])==0):\n",
    "            answer_list[i][1]=\"$\"\n",
    "        pred_answers.append(answer_list[i][0])\n",
    "        true_answers.append(answer_list[i][1])\n",
    "    wer_score = wer.compute(predictions=pred_answers, references=true_answers)\n",
    "    print(\"epoch \",epoch,\":\",wer_score)\n",
    "    wer_list.append(wer_score)\n",
    "with open(\"base_model_wer.txt\", 'w') as f:\n",
    "    for s in wer_list:\n",
    "        f.write(str(s) + '\\n')\n",
    "print(wer_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
